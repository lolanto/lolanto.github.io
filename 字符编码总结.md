# 字符编码总结

---



“警告：XXX文件含有不能在当前代码页表示的字符”

"错误：(1,1)非法字符"

"x&%@#^*)&%"

...

以上总总，都是和字符相关的问题。在编程过程中，凡是涉及到字符的，特别是需要对文本进行处理，需要设置路径等问题时，都需要有编码的意识。

## 重要概念

### 1. Abstract character repertoire (抽象字符表)

代表一个系统能够支持的所有字符的集合

### 2. Coded Character Set (编码字符集)

字符集将字符表中的每个字符都映射到独立的非负整数，或者向量(二维向量)中，字符集是字符到数字(标志)的映射关系。比如有字符表中有26个英文字母，字符集记录了1~26整数分别与26个英文字母一一对应。

### 3. Character Encoding Form (字符编码表)

通过查询字符集，获得了每个字符的标志后，需要将标志转换成计算机可以识别的二进制组合。编码表就是标志与二进制组合之间的映射关系。

### 4. Character Encoding Scheme(字符编码方案)

在获得每个字符的二进制组合后，需要针对具体实现，确定如何记录这些二进制组合。比如UTF-8，使用多个字节来存储Unicode的编码，而ASCII使用一个字节存储所有的二进制组合。

## 常见名词解释

以下对几个常见的名词结合上述概念进行解析

### ASCII

ASCII很简单，它仅使用7个二进制位(字符数量需求少)，对英文字符，标点以及阿拉伯数字进行编码，也就是说，它是一个编码方案。在计算机当中，存储ASCII，每个字符仅使用一个字节即可。(在ASCII诞生后，某些地区由于有更多的字符需求，所以把ASCII扩展成8位，比如EASCII)

### Unicode

Unicode是字符编码表，该编码表对应的字符表基本包含了世界上所有语言使用到的字符。也就是每个字符都有对应的整数，并且有对应的二进制表达形式。但Unicode并不是编码方案，UTF-8，UTF-16就是Unicode的具体的编码方案之一。

### ANSI

可以理解为是各个地区针对各自的文字系统制定的文字编码的统称(编码方案)，特别是亚洲地区。对于中国大陆的系统而言，ANSI意味着使用GBK编码，而日本地区使用JIS，使用繁体字的地区通常使用Big5编码。它们都有明确的字节规定，但字节数不一定统一。

### 多字节字符与宽字节字符

这是编码方案层面上的概念， 多字节字符意味着一个字符可能由1个，2个甚至更多的字节构成，也可以理解为变字节字符。宽字节字符意味着一个字符占用的字节数是固定的，比如2个字节。

这两个概念下又对应着多种具体的编码方案，所以如windows api提供的多字节字符到宽字节字符的转换，都需要清楚具体转换的是哪两个编码方案。

## UTF-8的编码方式

UTF-8是多字节字符，其兼容ASCII，同时节省空间，所以经常在网络上传输使用。

UTF-8的编码方式比较特别，它的每个字节中，都有几位是保留用于解析。

比如某个字符其Unicode编码可以使用10位二进制表示，比如(1024)，那么UTF-8就需要使用2个字节表示；而一个16位二进制可表示的数字，UTF-8需要使用3个字节表示。

具体的编码方式这里不做赘述。

部分系统对UTF-8编码的文本，会在文本开头添加BOM(字节序)作为标记。BOM实际上是为了克服大小端问题，但UTF-8本身是字节序无关的，BOM标记成了给文本编辑器提示编码格式的标记，但这并不绝对。

笔者在编程过程中觉得使用UTF-8的一个好处是在兼容ASCII前提下，保证在各个平台都不会乱码(依赖Unicode)。然而在使用过程中需要注意以下几点：

1. 把UTF-8当作ASCII给编译器处理时，需要提防UTF-8开头的BOM
2. Windows根据BOM判断处理的编码是否为UTF-8，当BOM去掉后，需要手动/显式告知文本处理器编码格式。
3. 编程过程中，统一文本编码方式

## 编码识别

由于编码方式很多，当未告知编码方式时，文本处理器通过词库的方式预测当前文本的编码方式。词库意味着某些字符总是顺序出现，即某些文本总是具有某些特定的字节序。当汉字篇幅较多，则文本中，汉字相关的词汇也多，相应的字节序列也多，故可猜测为中文编码。